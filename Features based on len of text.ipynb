{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kunal/Downloads/lord_of_machines/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "campaign = pd.read_csv(path +'campaign_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.read_csv(path + 'impact_encoded_train.csv')\n",
    "test_input = pd.read_csv(path + 'impact_encoded_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE EXTRA FEATURES USING GROUPBY STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(campaign, on ='campaign_id',how = 'left')\n",
    "test = test.merge(campaign, on ='campaign_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x1 = train.groupby('campaign_id')['is_click'].mean().sort_values(ascending = False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x3 = train.groupby('campaign_id')['is_open'].mean().sort_values(ascending = False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x2 = train['campaign_id'].value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_time(cell):\n",
    "#    cell = cell.split(' ')[-1]\n",
    "#    cell = cell.split(':')[0]\n",
    "#    return cell\n",
    "#train['hour'] = train['send_date'].apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train[train['is_click'] == 1].hour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x5 = train['hour'].value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test['hour'] = test['send_date'].apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test['hour'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.read_csv(path + 'impact_encoded_train.csv')\n",
    "test_input = pd.read_csv(path + 'impact_encoded_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x3 = train.groupby('hour')['is_open'].mean().sort_values(ascending = False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Day of the week\n",
    "#def get_date(cell):\n",
    "#    return cell.split(' ')[0]\n",
    "#train['date'] = train['send_date'].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import datetime\n",
    "#exp = train['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_weekday(cell):\n",
    "#    return datetime.strptime(cell,'%d-%m-%Y').weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['weekday'] = train['date'].apply(get_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['weekday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test['date'] = test['send_date'].apply(get_date)\n",
    "#test['weekday'] = test['date'].apply(get_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr.groupby('weekday')['is_open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.groupby('hour')['is_open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "campaign['len_sub'] = campaign['subject'].str.split(' ').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_sub'] = train['campaign_id'].map(pd.Series(campaign['len_sub'],index = campaign['campaign_id']))\n",
    "test['len_sub'] = test['campaign_id'].map(pd.Series(campaign['len_sub'],index = campaign['campaign_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "campaign['len_sub_email'] = campaign['email_body'].str.split(' ').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_sub_email'] = train['campaign_id'].map(pd.Series(campaign['len_sub_email'],index = campaign['campaign_id']))\n",
    "test['len_sub_email'] = test['campaign_id'].map(pd.Series(campaign['len_sub_email'],index = campaign['campaign_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['len_sub','len_sub_email'],axis = 1,inplace = True)\n",
    "test.drop(['len_sub','len_sub_email'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(campaign[['campaign_id','len_sub','len_sub_email']],on = 'campaign_id',how = 'left')\n",
    "test = test.merge(campaign[['campaign_id','len_sub','len_sub_email']],on = 'campaign_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input['len_sub'] = train['len_sub']\n",
    "train_input['len_sub_email'] = train['len_sub_email']\n",
    "\n",
    "test_input['len_sub'] = test['len_sub']\n",
    "test_input['len_sub_email'] = test['len_sub_email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input.to_csv(path + 'impact_encoded_train.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input.to_csv(path + 'impact_encoded_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This way we have randomness and are able to reproduce the behaviour within this cell.\n",
    "np.random.seed(13)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def impact_coding(data, feature, target='y'):\n",
    "    '''\n",
    "    In this implementation we get the values and the dictionary as two different steps.\n",
    "    This is just because initially we were ignoring the dictionary as a result variable.\n",
    "    \n",
    "    In this implementation the KFolds use shuffling. If you want reproducibility the cv \n",
    "    could be moved to a parameter.\n",
    "    '''\n",
    "    n_folds = 10\n",
    "    n_inner_folds = 5\n",
    "    impact_coded = pd.Series()\n",
    "    \n",
    "    oof_default_mean = data[target].mean() # Gobal mean to use by default (you could further tune this)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    oof_mean_cv = pd.DataFrame()\n",
    "    split = 0\n",
    "    for infold, oof in kf.split(data[feature]):\n",
    "            impact_coded_cv = pd.Series()\n",
    "            kf_inner = KFold(n_splits=n_inner_folds, shuffle=True)\n",
    "            inner_split = 0\n",
    "            inner_oof_mean_cv = pd.DataFrame()\n",
    "            oof_default_inner_mean = data.iloc[infold][target].mean()\n",
    "            for infold_inner, oof_inner in kf_inner.split(data.iloc[infold]):\n",
    "                # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n",
    "                oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "                impact_coded_cv = impact_coded_cv.append(data.iloc[infold].apply(\n",
    "                            lambda x: oof_mean[x[feature]]\n",
    "                                      if x[feature] in oof_mean.index\n",
    "                                      else oof_default_inner_mean\n",
    "                            , axis=1))\n",
    "\n",
    "                # Also populate mapping (this has all group -> mean for all inner CV folds)\n",
    "                inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n",
    "                inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n",
    "                inner_split += 1\n",
    "\n",
    "            # Also populate mapping\n",
    "            oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n",
    "            oof_mean_cv.fillna(value=oof_default_mean, inplace=True)\n",
    "            split += 1\n",
    "            \n",
    "            impact_coded = impact_coded.append(data.iloc[oof].apply(\n",
    "                            lambda x: inner_oof_mean_cv.loc[x[feature]].mean()\n",
    "                                      if x[feature] in inner_oof_mean_cv.index\n",
    "                                      else oof_default_mean\n",
    "                            , axis=1))\n",
    "\n",
    "    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = 'weekday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the encoding to training and test data, and preserve the mapping\n",
    "impact_coding_map = {}\n",
    "print(\"Impact coding for {}\".format(f))\n",
    "train[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train, f,'is_click')\n",
    "impact_coding_map[f] = (impact_coding_mapping, default_coding)\n",
    "mapping, default_mean = impact_coding_map[f]\n",
    "test[\"impact_encoded_{}\".format(f)] = test.apply(lambda x: mapping[x[f]]\n",
    "                                                                     if x[f] in mapping\n",
    "                                                                     else default_mean\n",
    "                                                           , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impact_coding_map = {}\n",
    "print(\"Impact coding for {}\".format(f))\n",
    "train[\"impact_encoded_open_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train, f,'is_open')\n",
    "impact_coding_map[f] = (impact_coding_mapping, default_coding)\n",
    "mapping, default_mean = impact_coding_map[f]\n",
    "test[\"impact_encoded_open_{}\".format(f)] = test.apply(lambda x: mapping[x[f]]\n",
    "                                                                     if x[f] in mapping\n",
    "                                                                     else default_mean\n",
    "                                                           , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
