{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kunal/Downloads/lord_of_machines/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "campaign = pd.read_csv(path +'campaign_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective is to create aggregate features and encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technique picked up from a kaggle forum. The code can be found here:https://www.kaggle.com/tnarik/likelihood-encoding-of-categorical-features/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This way we have randomness and are able to reproduce the behaviour within this cell.\n",
    "np.random.seed(13)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def impact_coding(data, feature, target='y'):\n",
    "    '''\n",
    "    In this implementation we get the values and the dictionary as two different steps.\n",
    "    This is just because initially we were ignoring the dictionary as a result variable.\n",
    "    \n",
    "    In this implementation the KFolds use shuffling. If you want reproducibility the cv \n",
    "    could be moved to a parameter.\n",
    "    '''\n",
    "    n_folds = 10\n",
    "    n_inner_folds = 5\n",
    "    impact_coded = pd.Series()\n",
    "    \n",
    "    oof_default_mean = data[target].mean() # Gobal mean to use by default (you could further tune this)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    oof_mean_cv = pd.DataFrame()\n",
    "    split = 0\n",
    "    for infold, oof in kf.split(data[feature]):\n",
    "            impact_coded_cv = pd.Series()\n",
    "            kf_inner = KFold(n_splits=n_inner_folds, shuffle=True)\n",
    "            inner_split = 0\n",
    "            inner_oof_mean_cv = pd.DataFrame()\n",
    "            oof_default_inner_mean = data.iloc[infold][target].mean()\n",
    "            for infold_inner, oof_inner in kf_inner.split(data.iloc[infold]):\n",
    "                # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n",
    "                oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "                impact_coded_cv = impact_coded_cv.append(data.iloc[infold].apply(\n",
    "                            lambda x: oof_mean[x[feature]]\n",
    "                                      if x[feature] in oof_mean.index\n",
    "                                      else oof_default_inner_mean\n",
    "                            , axis=1))\n",
    "\n",
    "                # Also populate mapping (this has all group -> mean for all inner CV folds)\n",
    "                inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n",
    "                inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n",
    "                inner_split += 1\n",
    "\n",
    "            # Also populate mapping\n",
    "            oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n",
    "            oof_mean_cv.fillna(value=oof_default_mean, inplace=True)\n",
    "            split += 1\n",
    "            \n",
    "            impact_coded = impact_coded.append(data.iloc[oof].apply(\n",
    "                            lambda x: inner_oof_mean_cv.loc[x[feature]].mean()\n",
    "                                      if x[feature] in inner_oof_mean_cv.index\n",
    "                                      else oof_default_mean\n",
    "                            , axis=1))\n",
    "\n",
    "    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Prepare dataset for encoding\n",
    "train = train.merge(campaign,on = 'campaign_id',how = 'left')\n",
    "test = test.merge(campaign, on = 'campaign_id',how = 'left')\n",
    "train['user_id'] = train['user_id'].apply(str)\n",
    "train['campaign_id'] = train['campaign_id'].apply(str)\n",
    "test['user_id'] = test['user_id'].apply(str)\n",
    "test['campaign_id'] = test['campaign_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['email_body', 'subject', 'email_url','send_date'],axis =1 )\n",
    "test = test.drop(['email_body', 'subject', 'email_url','send_date'],axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'user_id', 'campaign_id', 'communication_type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train.columns\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "\n",
    "for dtype, feature in zip(train.dtypes, train.columns):\n",
    "    if dtype == object:\n",
    "        #print(column)\n",
    "        #print(train_data[column].describe())\n",
    "        categorical_features.append(feature)\n",
    "    else:\n",
    "        numeric_features.append(feature)\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact coding for user_id\n",
      "Impact coding for campaign_id\n",
      "Impact coding for communication_type\n"
     ]
    }
   ],
   "source": [
    "# Apply the encoding to training and test data, and preserve the mapping\n",
    "impact_coding_map = {}\n",
    "for f in categorical_features[1:]:\n",
    "    print(\"Impact coding for {}\".format(f))\n",
    "    train[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train, f,'is_click')\n",
    "    impact_coding_map[f] = (impact_coding_mapping, default_coding)\n",
    "    mapping, default_mean = impact_coding_map[f]\n",
    "    test[\"impact_encoded_{}\".format(f)] = test.apply(lambda x: mapping[x[f]]\n",
    "                                                                         if x[f] in mapping\n",
    "                                                                         else default_mean\n",
    "                                                               , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact coding for user_id\n",
      "Impact coding for campaign_id\n",
      "Impact coding for communication_type\n"
     ]
    }
   ],
   "source": [
    "impact_coding_map = {}\n",
    "for f in categorical_features[1:]:\n",
    "    print(\"Impact coding for {}\".format(f))\n",
    "    train[\"impact_encoded_open_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train, f,'is_open')\n",
    "    impact_coding_map[f] = (impact_coding_mapping, default_coding)\n",
    "    mapping, default_mean = impact_coding_map[f]\n",
    "    test[\"impact_encoded_open_{}\".format(f)] = test.apply(lambda x: mapping[x[f]]\n",
    "                                                                         if x[f] in mapping\n",
    "                                                                         else default_mean\n",
    "                                                               , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(path + 'impact_encoded_train.csv',index = False)\n",
    "test.to_csv(path + 'impact_encoded_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
